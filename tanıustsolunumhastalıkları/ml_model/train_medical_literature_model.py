#!/usr/bin/env python3
"""
Train Medical Literature Model
TÄ±bbi literatÃ¼r verilerine dayalÄ± model eÄŸitimi
"""

import pandas as pd
import numpy as np
import joblib
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

class MedicalLiteratureModelTrainer:
    def __init__(self, data_file="medical_literature_dataset.csv"):
        """TÄ±bbi literatÃ¼r modeli eÄŸitici"""
        print("ğŸ¥ TÄ±bbi LiteratÃ¼r Modeli EÄŸitici baÅŸlatÄ±lÄ±yor...")
        
        self.data_file = data_file
        self.models = {}
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.best_model = None
        
        # Semptom listesi
        self.symptoms = [
            "AteÅŸ", "BaÅŸ AÄŸrÄ±sÄ±", "Bitkinlik", "BoÄŸaz AÄŸrÄ±sÄ±", "BulantÄ± veya Kusma",
            "Burun AkÄ±ntÄ±sÄ± veya TÄ±kanÄ±klÄ±ÄŸÄ±", "GÃ¶z KaÅŸÄ±ntÄ±sÄ± veya Sulanma", "HapÅŸÄ±rma",
            "Ä°shal", "Koku veya Tat KaybÄ±", "Nefes DarlÄ±ÄŸÄ±", "Ã–ksÃ¼rÃ¼k", "VÃ¼cut AÄŸrÄ±larÄ±",
            "GÃ¶ÄŸÃ¼s AÄŸrÄ±sÄ±", "Titreme", "Gece Terlemesi", "Ä°ÅŸtahsÄ±zlÄ±k", "Konsantrasyon GÃ¼Ã§lÃ¼ÄŸÃ¼"
        ]
        
        print(f"âœ… {len(self.symptoms)} semptom iÃ§in model eÄŸitici hazÄ±r")
    
    def load_data(self):
        """Veri setini yÃ¼kle"""
        print(f"ğŸ“‚ Veri seti yÃ¼kleniyor: {self.data_file}")
        
        try:
            self.df = pd.read_csv(self.data_file)
            print(f"âœ… {len(self.df):,} hasta verisi yÃ¼klendi")
            print(f"ğŸ“Š HastalÄ±k daÄŸÄ±lÄ±mÄ±:")
            print(self.df['Hastalik'].value_counts())
            return True
        except FileNotFoundError:
            print(f"âŒ Veri dosyasÄ± bulunamadÄ±: {self.data_file}")
            return False
    
    def prepare_data(self):
        """Veriyi hazÄ±rla"""
        print("ğŸ”§ Veri hazÄ±rlanÄ±yor...")
        
        # Semptom verilerini al
        X = self.df[self.symptoms].values
        y = self.df['Hastalik'].values
        
        print(f"ğŸ“Š Veri boyutlarÄ±: {X.shape}")
        print(f"ğŸ¯ Hedef sÄ±nÄ±flarÄ±: {np.unique(y)}")
        
        # Train-test split
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"âœ… Train set: {self.X_train.shape[0]:,} hasta")
        print(f"âœ… Test set: {self.X_test.shape[0]:,} hasta")
        
        return True
    
    def create_enhanced_features(self):
        """GeliÅŸmiÅŸ Ã¶zellikler oluÅŸtur"""
        print("ğŸš€ GeliÅŸmiÅŸ Ã¶zellikler oluÅŸturuluyor...")
        
        def create_features(data):
            features = []
            
            # Temel semptomlar (18 adet)
            for symptom in self.symptoms:
                features.append(data[self.symptoms.index(symptom)])
            
            # COVID-19 Ã¶zel Ã¶zellikler
            covid_features = [
                data[self.symptoms.index("Koku veya Tat KaybÄ±")],
                data[self.symptoms.index("Nefes DarlÄ±ÄŸÄ±")],
                data[self.symptoms.index("Koku veya Tat KaybÄ±")] * data[self.symptoms.index("Nefes DarlÄ±ÄŸÄ±")],  # EtkileÅŸim
                data[self.symptoms.index("AteÅŸ")] * data[self.symptoms.index("Ã–ksÃ¼rÃ¼k")],  # EtkileÅŸim
            ]
            features.extend(covid_features)
            
            # Grip Ã¶zel Ã¶zellikler
            flu_features = [
                data[self.symptoms.index("VÃ¼cut AÄŸrÄ±larÄ±")],
                data[self.symptoms.index("Titreme")],
                data[self.symptoms.index("VÃ¼cut AÄŸrÄ±larÄ±")] * data[self.symptoms.index("Titreme")],  # EtkileÅŸim
                data[self.symptoms.index("AteÅŸ")] * data[self.symptoms.index("VÃ¼cut AÄŸrÄ±larÄ±")],  # EtkileÅŸim
            ]
            features.extend(flu_features)
            
            # SoÄŸuk algÄ±nlÄ±ÄŸÄ± Ã¶zel Ã¶zellikler
            cold_features = [
                data[self.symptoms.index("Burun AkÄ±ntÄ±sÄ± veya TÄ±kanÄ±klÄ±ÄŸÄ±")],
                data[self.symptoms.index("HapÅŸÄ±rma")],
                data[self.symptoms.index("Burun AkÄ±ntÄ±sÄ± veya TÄ±kanÄ±klÄ±ÄŸÄ±")] * data[self.symptoms.index("HapÅŸÄ±rma")],  # EtkileÅŸim
                data[self.symptoms.index("BoÄŸaz AÄŸrÄ±sÄ±")] * data[self.symptoms.index("Ã–ksÃ¼rÃ¼k")],  # EtkileÅŸim
            ]
            features.extend(cold_features)
            
            # Alerji Ã¶zel Ã¶zellikler
            allergy_features = [
                data[self.symptoms.index("GÃ¶z KaÅŸÄ±ntÄ±sÄ± veya Sulanma")],
                data[self.symptoms.index("GÃ¶z KaÅŸÄ±ntÄ±sÄ± veya Sulanma")] * data[self.symptoms.index("HapÅŸÄ±rma")],  # EtkileÅŸim
                data[self.symptoms.index("AteÅŸ")] == 0,  # AteÅŸ yok (boolean)
                data[self.symptoms.index("VÃ¼cut AÄŸrÄ±larÄ±")] == 0,  # VÃ¼cut aÄŸrÄ±sÄ± yok (boolean)
            ]
            features.extend(allergy_features)
            
            # Genel Ã¶zellikler
            general_features = [
                np.sum(data),  # Toplam semptom yoÄŸunluÄŸu
                np.sum(data > 0),  # Aktif semptom sayÄ±sÄ±
                np.max(data),  # Maksimum semptom yoÄŸunluÄŸu
                np.std(data),  # Semptom yoÄŸunluÄŸu standart sapmasÄ±
                np.mean(data),  # Ortalama semptom yoÄŸunluÄŸu
            ]
            features.extend(general_features)
            
            return np.array(features)
        
        # Train ve test setleri iÃ§in Ã¶zellikler oluÅŸtur
        self.X_train_enhanced = np.array([create_features(x) for x in self.X_train])
        self.X_test_enhanced = np.array([create_features(x) for x in self.X_test])
        
        print(f"âœ… GeliÅŸmiÅŸ Ã¶zellikler oluÅŸturuldu: {self.X_train_enhanced.shape[1]} Ã¶zellik")
        
        return True
    
    def scale_features(self):
        """Ã–zellikleri Ã¶lÃ§eklendir"""
        print("ğŸ“ Ã–zellikler Ã¶lÃ§eklendiriliyor...")
        
        self.X_train_scaled = self.scaler.fit_transform(self.X_train_enhanced)
        self.X_test_scaled = self.scaler.transform(self.X_test_enhanced)
        
        print("âœ… Ã–zellikler Ã¶lÃ§eklendirildi")
        
        return True
    
    def select_features(self):
        """En iyi Ã¶zellikleri seÃ§"""
        print("ğŸ¯ En iyi Ã¶zellikler seÃ§iliyor...")
        
        # En iyi 25 Ã¶zelliÄŸi seÃ§
        self.feature_selector = SelectKBest(score_func=f_classif, k=25)
        self.X_train_selected = self.feature_selector.fit_transform(self.X_train_scaled, self.y_train)
        self.X_test_selected = self.feature_selector.transform(self.X_test_scaled)
        
        print(f"âœ… {self.X_train_selected.shape[1]} en iyi Ã¶zellik seÃ§ildi")
        
        return True
    
    def train_models(self):
        """Modelleri eÄŸit"""
        print("ğŸ¤– Modeller eÄŸitiliyor...")
        
        # Model tanÄ±mlarÄ±
        self.models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                min_samples_leaf=3,
                random_state=42,
                n_jobs=-1
            ),
            'SVM': SVC(
                kernel='rbf',
                C=1.0,
                gamma='scale',
                probability=True,
                random_state=42
            ),
            'NeuralNetwork': MLPClassifier(
                hidden_layer_sizes=(100, 50),
                max_iter=500,
                random_state=42
            ),
            'LogisticRegression': LogisticRegression(
                max_iter=1000,
                random_state=42
            ),
            'Bagging': BaggingClassifier(
                estimator=RandomForestClassifier(n_estimators=100, random_state=42),
                n_estimators=10,
                random_state=42,
                n_jobs=-1
            )
        }
        
        # Her modeli eÄŸit
        model_scores = {}
        
        for name, model in self.models.items():
            print(f"   ğŸ”„ {name} eÄŸitiliyor...")
            
            # Modeli eÄŸit
            model.fit(self.X_train_selected, self.y_train)
            
            # Cross-validation skoru
            cv_scores = cross_val_score(model, self.X_train_selected, self.y_train, cv=5)
            model_scores[name] = cv_scores.mean()
            
            print(f"   âœ… {name} CV Skoru: %{cv_scores.mean()*100:.2f}")
        
        # En iyi modelleri seÃ§
        best_models = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)[:4]
        
        print(f"\nğŸ† En iyi 4 model:")
        for name, score in best_models:
            print(f"   {name}: %{score*100:.2f}")
        
        # Ensemble model oluÅŸtur
        ensemble_models = [(name, self.models[name]) for name, _ in best_models]
        
        self.best_model = VotingClassifier(
            estimators=ensemble_models,
            voting='soft'
        )
        
        # Ensemble modeli eÄŸit
        print(f"\nğŸ¯ Ensemble model eÄŸitiliyor...")
        self.best_model.fit(self.X_train_selected, self.y_train)
        
        # Ensemble CV skoru
        ensemble_cv = cross_val_score(self.best_model, self.X_train_selected, self.y_train, cv=5)
        print(f"âœ… Ensemble CV Skoru: %{ensemble_cv.mean()*100:.2f}")
        
        return True
    
    def evaluate_model(self):
        """Modeli deÄŸerlendir"""
        print("ğŸ“Š Model deÄŸerlendiriliyor...")
        
        # Test tahminleri
        y_pred = self.best_model.predict(self.X_test_selected)
        y_pred_proba = self.best_model.predict_proba(self.X_test_selected)
        
        # Accuracy
        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"ğŸ¯ Test Accuracy: %{accuracy*100:.2f}")
        
        # Classification report
        print(f"\nğŸ“‹ Classification Report:")
        print(classification_report(self.y_test, y_pred))
        
        # Confusion matrix
        cm = confusion_matrix(self.y_test, y_pred)
        print(f"\nğŸ”¢ Confusion Matrix:")
        print(cm)
        
        # HastalÄ±k bazÄ±nda doÄŸruluk
        diseases = np.unique(self.y_test)
        print(f"\nğŸ¥ HastalÄ±k BazÄ±nda DoÄŸruluk:")
        for i, disease in enumerate(diseases):
            disease_accuracy = cm[i, i] / cm[i, :].sum()
            print(f"   {disease}: %{disease_accuracy*100:.2f}")
        
        return accuracy
    
    def save_model(self):
        """Modeli kaydet"""
        print("ğŸ’¾ Model kaydediliyor...")
        
        # Model ve preprocessing nesnelerini kaydet
        model_data = {
            'model': self.best_model,
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'symptoms': self.symptoms,
            'accuracy': self.evaluate_model()
        }
        
        joblib.dump(model_data, 'medical_literature_model.pkl')
        print("âœ… Model 'medical_literature_model.pkl' olarak kaydedildi")
        
        return True
    
    def run_training_pipeline(self):
        """EÄŸitim pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ TIBBÄ° LÄ°TERATÃœR MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR...")
        print("="*60)
        
        # Pipeline adÄ±mlarÄ±
        steps = [
            ("Veri YÃ¼kleme", self.load_data),
            ("Veri HazÄ±rlama", self.prepare_data),
            ("GeliÅŸmiÅŸ Ã–zellikler", self.create_enhanced_features),
            ("Ã–zellik Ã–lÃ§eklendirme", self.scale_features),
            ("Ã–zellik SeÃ§imi", self.select_features),
            ("Model EÄŸitimi", self.train_models),
            ("Model DeÄŸerlendirme", self.evaluate_model),
            ("Model Kaydetme", self.save_model)
        ]
        
        for step_name, step_func in steps:
            print(f"\nğŸ”„ {step_name}...")
            if not step_func():
                print(f"âŒ {step_name} baÅŸarÄ±sÄ±z!")
                return False
            print(f"âœ… {step_name} tamamlandÄ±!")
        
        print(f"\nğŸ‰ TIBBÄ° LÄ°TERATÃœR MODEL EÄÄ°TÄ°MÄ° TAMAMLANDI!")
        print("="*60)
        
        return True

def main():
    """Ana fonksiyon"""
    trainer = MedicalLiteratureModelTrainer()
    trainer.run_training_pipeline()

if __name__ == "__main__":
    main()
