#!/usr/bin/env python3
"""
Profesyonel TÄ±bbi AI Model EÄŸitim ve DoÄŸrulama Sistemi
====================================================

Bu script tÃ¼m tÄ±bbi gÃ¶rÃ¼ntÃ¼ analizi modellerini eÄŸitir, doÄŸrular ve
profesyonel seviyede sonuÃ§lar Ã¼retir.

KullanÄ±m:
    python train_all_models.py

Yazar: Dr. AI Research Team
Tarih: 2024
Versiyon: 2.0.0
"""

import sys
import logging
import argparse
from pathlib import Path
import time
from datetime import datetime

# Proje root'unu Python path'e ekle
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Custom imports
from models.train_models import ProfessionalModelTrainer
from models.data_manager import MedicalDatasetManager
from models.model_validator import ProfessionalModelValidator

# Logging ayarla
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ProfessionalTrainingPipeline:
    """Profesyonel eÄŸitim pipeline'Ä±"""
    
    def __init__(self, 
                 models_dir: str = "models",
                 data_dir: str = "data",
                 results_dir: str = "results"):
        self.models_dir = models_dir
        self.data_dir = data_dir
        self.results_dir = results_dir
        
        # BileÅŸenleri baÅŸlat
        self.data_manager = MedicalDatasetManager(data_dir)
        self.trainer = ProfessionalModelTrainer(models_dir, data_dir, results_dir)
        self.validator = ProfessionalModelValidator(models_dir, data_dir, f"{results_dir}/validation")
        
        logger.info("ðŸ¥ Profesyonel TÄ±bbi AI EÄŸitim Pipeline'Ä± baÅŸlatÄ±ldÄ±")
    
    def run_complete_pipeline(self, 
                            skip_data_preparation: bool = False,
                            skip_training: bool = False,
                            skip_validation: bool = False) -> Dict[str, Any]:
        """Tam eÄŸitim pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±r"""
        start_time = time.time()
        pipeline_results = {
            'start_time': datetime.now().isoformat(),
            'steps_completed': [],
            'errors': [],
            'summary': {}
        }
        
        try:
            # 1. Veri HazÄ±rlama
            if not skip_data_preparation:
                logger.info("ðŸ“Š AdÄ±m 1: Veri Setleri HazÄ±rlanÄ±yor...")
                data_results = self._prepare_all_datasets()
                pipeline_results['steps_completed'].append('data_preparation')
                pipeline_results['data_preparation'] = data_results
                
                if not data_results['success']:
                    logger.error("Veri hazÄ±rlama baÅŸarÄ±sÄ±z!")
                    return pipeline_results
            
            # 2. Model EÄŸitimi
            if not skip_training:
                logger.info("ðŸ¤– AdÄ±m 2: Modeller EÄŸitiliyor...")
                training_results = self._train_all_models()
                pipeline_results['steps_completed'].append('training')
                pipeline_results['training'] = training_results
                
                if not training_results['success']:
                    logger.error("Model eÄŸitimi baÅŸarÄ±sÄ±z!")
                    return pipeline_results
            
            # 3. Model DoÄŸrulama
            if not skip_validation:
                logger.info("ðŸ” AdÄ±m 3: Modeller DoÄŸrulanÄ±yor...")
                validation_results = self._validate_all_models()
                pipeline_results['steps_completed'].append('validation')
                pipeline_results['validation'] = validation_results
            
            # 4. Ã–zet Rapor
            logger.info("ðŸ“‹ AdÄ±m 4: Ã–zet Rapor OluÅŸturuluyor...")
            summary = self._create_pipeline_summary(pipeline_results)
            pipeline_results['summary'] = summary
            
            # Pipeline tamamlandÄ±
            end_time = time.time()
            pipeline_results['end_time'] = datetime.now().isoformat()
            pipeline_results['total_duration'] = end_time - start_time
            pipeline_results['success'] = True
            
            logger.info(f"ðŸŽ‰ Pipeline baÅŸarÄ±yla tamamlandÄ±! SÃ¼re: {pipeline_results['total_duration']:.2f} saniye")
            
        except Exception as e:
            logger.error(f"Pipeline hatasÄ±: {str(e)}")
            pipeline_results['errors'].append(str(e))
            pipeline_results['success'] = False
        
        return pipeline_results
    
    def _prepare_all_datasets(self) -> Dict[str, Any]:
        """TÃ¼m veri setlerini hazÄ±rla"""
        try:
            datasets = self.data_manager.list_available_datasets()
            results = {
                'success': True,
                'datasets': {},
                'total_datasets': len(datasets),
                'successful_datasets': 0,
                'failed_datasets': 0
            }
            
            for dataset_name in datasets.keys():
                logger.info(f"Veri seti hazÄ±rlanÄ±yor: {dataset_name}")
                
                try:
                    success = self.data_manager.download_dataset(dataset_name)
                    
                    if success:
                        # Veri setini doÄŸrula
                        validation = self.data_manager.validate_dataset(dataset_name)
                        
                        results['datasets'][dataset_name] = {
                            'prepared': True,
                            'validation': validation,
                            'total_samples': validation.get('total_samples', 0)
                        }
                        
                        if validation['valid']:
                            results['successful_datasets'] += 1
                            logger.info(f"âœ… {dataset_name}: {validation['total_samples']} Ã¶rnek")
                        else:
                            results['failed_datasets'] += 1
                            logger.error(f"âŒ {dataset_name}: {validation['errors']}")
                    else:
                        results['datasets'][dataset_name] = {'prepared': False, 'error': 'HazÄ±rlama baÅŸarÄ±sÄ±z'}
                        results['failed_datasets'] += 1
                        
                except Exception as e:
                    logger.error(f"Veri seti hazÄ±rlama hatasÄ± ({dataset_name}): {str(e)}")
                    results['datasets'][dataset_name] = {'prepared': False, 'error': str(e)}
                    results['failed_datasets'] += 1
            
            if results['successful_datasets'] == 0:
                results['success'] = False
            
            return results
            
        except Exception as e:
            logger.error(f"Veri hazÄ±rlama hatasÄ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _train_all_models(self) -> Dict[str, Any]:
        """TÃ¼m modelleri eÄŸit"""
        try:
            logger.info("Model eÄŸitimi baÅŸlatÄ±lÄ±yor...")
            results = self.trainer.train_all_models()
            
            # SonuÃ§larÄ± analiz et
            successful_models = len([r for r in results.values() if 'error' not in r])
            failed_models = len([r for r in results.values() if 'error' in r])
            
            training_summary = {
                'success': successful_models > 0,
                'total_models': len(results),
                'successful_models': successful_models,
                'failed_models': failed_models,
                'results': results
            }
            
            # BaÅŸarÄ±lÄ± modelleri logla
            logger.info("ðŸ“Š EÄŸitim SonuÃ§larÄ±:")
            for model_name, result in results.items():
                if 'error' not in result:
                    logger.info(f"âœ… {model_name}: {result['final_accuracy']:.2f}% accuracy")
                else:
                    logger.error(f"âŒ {model_name}: {result['error']}")
            
            return training_summary
            
        except Exception as e:
            logger.error(f"Model eÄŸitimi hatasÄ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _validate_all_models(self) -> Dict[str, Any]:
        """TÃ¼m modelleri doÄŸrula"""
        try:
            logger.info("Model doÄŸrulamasÄ± baÅŸlatÄ±lÄ±yor...")
            results = self.validator.validate_all_models()
            
            # SonuÃ§larÄ± analiz et
            successful_validations = len([r for r in results.values() if 'error' not in r])
            failed_validations = len([r for r in results.values() if 'error' in r])
            
            validation_summary = {
                'success': successful_validations > 0,
                'total_models': len(results),
                'successful_validations': successful_validations,
                'failed_validations': failed_validations,
                'results': results
            }
            
            # DoÄŸrulama sonuÃ§larÄ±nÄ± logla
            logger.info("ðŸ” DoÄŸrulama SonuÃ§larÄ±:")
            for model_name, result in results.items():
                if 'error' not in result:
                    logger.info(f"âœ… {model_name}: {result['accuracy']:.4f} accuracy")
                else:
                    logger.error(f"âŒ {model_name}: {result['error']}")
            
            return validation_summary
            
        except Exception as e:
            logger.error(f"Model doÄŸrulamasÄ± hatasÄ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _create_pipeline_summary(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """Pipeline Ã¶zeti oluÅŸtur"""
        summary = {
            'pipeline_success': pipeline_results.get('success', False),
            'steps_completed': pipeline_results.get('steps_completed', []),
            'total_duration': pipeline_results.get('total_duration', 0),
            'model_performance': {},
            'recommendations': []
        }
        
        # Model performanslarÄ±nÄ± Ã¶zetle
        if 'validation' in pipeline_results:
            validation_results = pipeline_results['validation']['results']
            
            for model_name, result in validation_results.items():
                if 'error' not in result:
                    summary['model_performance'][model_name] = {
                        'accuracy': result.get('accuracy', 0.0),
                        'precision': result.get('precision', 0.0),
                        'recall': result.get('recall', 0.0),
                        'f1_score': result.get('f1_score', 0.0),
                        'auc_roc': result.get('auc_roc', 0.0)
                    }
        
        # Ã–neriler oluÅŸtur
        if summary['model_performance']:
            best_model = max(summary['model_performance'].items(), 
                           key=lambda x: x[1]['accuracy'])
            summary['recommendations'].append(f"En iyi performans: {best_model[0]} ({best_model[1]['accuracy']:.4f})")
            
            # DÃ¼ÅŸÃ¼k performanslÄ± modelleri belirle
            low_performance = [name for name, perf in summary['model_performance'].items() 
                             if perf['accuracy'] < 0.8]
            if low_performance:
                summary['recommendations'].append(f"DÃ¼ÅŸÃ¼k performanslÄ± modeller: {', '.join(low_performance)}")
        
        return summary


def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(description='Profesyonel TÄ±bbi AI Model EÄŸitim Sistemi')
    parser.add_argument('--skip-data', action='store_true', help='Veri hazÄ±rlamayÄ± atla')
    parser.add_argument('--skip-training', action='store_true', help='Model eÄŸitimini atla')
    parser.add_argument('--skip-validation', action='store_true', help='Model doÄŸrulamasÄ±nÄ± atla')
    parser.add_argument('--models-dir', default='models', help='Modeller dizini')
    parser.add_argument('--data-dir', default='data', help='Veri dizini')
    parser.add_argument('--results-dir', default='results', help='SonuÃ§lar dizini')
    
    args = parser.parse_args()
    
    logger.info("ðŸš€ Profesyonel TÄ±bbi AI Model EÄŸitim Sistemi BaÅŸlatÄ±lÄ±yor")
    logger.info(f"Modeller dizini: {args.models_dir}")
    logger.info(f"Veri dizini: {args.data_dir}")
    logger.info(f"SonuÃ§lar dizini: {args.results_dir}")
    
    # Pipeline oluÅŸtur ve Ã§alÄ±ÅŸtÄ±r
    pipeline = ProfessionalTrainingPipeline(
        models_dir=args.models_dir,
        data_dir=args.data_dir,
        results_dir=args.results_dir
    )
    
    # Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
    results = pipeline.run_complete_pipeline(
        skip_data_preparation=args.skip_data,
        skip_training=args.skip_training,
        skip_validation=args.skip_validation
    )
    
    # SonuÃ§larÄ± Ã¶zetle
    if results['success']:
        logger.info("ðŸŽ‰ Pipeline baÅŸarÄ±yla tamamlandÄ±!")
        
        if 'summary' in results:
            summary = results['summary']
            logger.info("ðŸ“Š Ã–zet:")
            logger.info(f"  - Tamamlanan adÄ±mlar: {', '.join(summary['steps_completed'])}")
            logger.info(f"  - Toplam sÃ¼re: {summary['total_duration']:.2f} saniye")
            
            if summary['recommendations']:
                logger.info("ðŸ’¡ Ã–neriler:")
                for rec in summary['recommendations']:
                    logger.info(f"  - {rec}")
    else:
        logger.error("âŒ Pipeline baÅŸarÄ±sÄ±z!")
        if results['errors']:
            logger.error("Hatalar:")
            for error in results['errors']:
                logger.error(f"  - {error}")
    
    # SonuÃ§larÄ± dosyaya kaydet
    import json
    results_file = Path(args.results_dir) / "pipeline_results.json"
    results_file.parent.mkdir(exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"SonuÃ§lar kaydedildi: {results_file}")


if __name__ == "__main__":
    main()
