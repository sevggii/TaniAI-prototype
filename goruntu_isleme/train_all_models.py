#!/usr/bin/env python3
"""
Profesyonel Tƒ±bbi AI Model Eƒüitim ve Doƒürulama Sistemi
====================================================

Bu script t√ºm tƒ±bbi g√∂r√ºnt√º analizi modellerini eƒüitir, doƒürular ve
profesyonel seviyede sonu√ßlar √ºretir.

Kullanƒ±m:
    python train_all_models.py

Yazar: Dr. AI Research Team
Tarih: 2024
Versiyon: 2.0.0
"""

import sys
import logging
import argparse
from pathlib import Path
import time
from datetime import datetime

# Proje root'unu Python path'e ekle
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Custom imports
from models.train_models import ProfessionalModelTrainer
from models.data_manager import MedicalDatasetManager
from models.model_validator import ProfessionalModelValidator

# Logging ayarla
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ProfessionalTrainingPipeline:
    """Profesyonel eƒüitim pipeline'ƒ±"""
    
    def __init__(self, 
                 models_dir: str = "models",
                 data_dir: str = "data",
                 results_dir: str = "results"):
        self.models_dir = models_dir
        self.data_dir = data_dir
        self.results_dir = results_dir
        
        # Bile≈üenleri ba≈ülat
        self.data_manager = MedicalDatasetManager(data_dir)
        self.trainer = ProfessionalModelTrainer(models_dir, data_dir, results_dir)
        self.validator = ProfessionalModelValidator(models_dir, data_dir, f"{results_dir}/validation")
        
        logger.info("üè• Profesyonel Tƒ±bbi AI Eƒüitim Pipeline'ƒ± ba≈ülatƒ±ldƒ±")
    
    def run_complete_pipeline(self, 
                            skip_data_preparation: bool = False,
                            skip_training: bool = False,
                            skip_validation: bool = False) -> Dict[str, Any]:
        """Tam eƒüitim pipeline'ƒ±nƒ± √ßalƒ±≈ütƒ±r"""
        start_time = time.time()
        pipeline_results = {
            'start_time': datetime.now().isoformat(),
            'steps_completed': [],
            'errors': [],
            'summary': {}
        }
        
        try:
            # 1. Veri Hazƒ±rlama
            if not skip_data_preparation:
                logger.info("üìä Adƒ±m 1: Veri Setleri Hazƒ±rlanƒ±yor...")
                data_results = self._prepare_all_datasets()
                pipeline_results['steps_completed'].append('data_preparation')
                pipeline_results['data_preparation'] = data_results
                
                if not data_results['success']:
                    logger.error("Veri hazƒ±rlama ba≈üarƒ±sƒ±z!")
                    return pipeline_results
            
            # 2. Model Eƒüitimi
            if not skip_training:
                logger.info("ü§ñ Adƒ±m 2: Modeller Eƒüitiliyor...")
                training_results = self._train_all_models()
                pipeline_results['steps_completed'].append('training')
                pipeline_results['training'] = training_results
                
                if not training_results['success']:
                    logger.error("Model eƒüitimi ba≈üarƒ±sƒ±z!")
                    return pipeline_results
            
            # 3. Model Doƒürulama
            if not skip_validation:
                logger.info("üîç Adƒ±m 3: Modeller Doƒürulanƒ±yor...")
                validation_results = self._validate_all_models()
                pipeline_results['steps_completed'].append('validation')
                pipeline_results['validation'] = validation_results
            
            # 4. √ñzet Rapor
            logger.info("üìã Adƒ±m 4: √ñzet Rapor Olu≈üturuluyor...")
            summary = self._create_pipeline_summary(pipeline_results)
            pipeline_results['summary'] = summary
            
            # Pipeline tamamlandƒ±
            end_time = time.time()
            pipeline_results['end_time'] = datetime.now().isoformat()
            pipeline_results['total_duration'] = end_time - start_time
            pipeline_results['success'] = True
            
            logger.info(f"üéâ Pipeline ba≈üarƒ±yla tamamlandƒ±! S√ºre: {pipeline_results['total_duration']:.2f} saniye")
            
        except Exception as e:
            logger.error(f"Pipeline hatasƒ±: {str(e)}")
            pipeline_results['errors'].append(str(e))
            pipeline_results['success'] = False
        
        return pipeline_results
    
    def _prepare_all_datasets(self) -> Dict[str, Any]:
        """T√ºm veri setlerini hazƒ±rla"""
        try:
            datasets = self.data_manager.list_available_datasets()
            results = {
                'success': True,
                'datasets': {},
                'total_datasets': len(datasets),
                'successful_datasets': 0,
                'failed_datasets': 0
            }
            
            for dataset_name in datasets.keys():
                logger.info(f"Veri seti hazƒ±rlanƒ±yor: {dataset_name}")
                
                try:
                    success = self.data_manager.download_dataset(dataset_name)
                    
                    if success:
                        # Veri setini doƒürula
                        validation = self.data_manager.validate_dataset(dataset_name)
                        
                        results['datasets'][dataset_name] = {
                            'prepared': True,
                            'validation': validation,
                            'total_samples': validation.get('total_samples', 0)
                        }
                        
                        if validation['valid']:
                            results['successful_datasets'] += 1
                            logger.info(f"‚úÖ {dataset_name}: {validation['total_samples']} √∂rnek")
                        else:
                            results['failed_datasets'] += 1
                            logger.error(f"‚ùå {dataset_name}: {validation['errors']}")
                    else:
                        results['datasets'][dataset_name] = {'prepared': False, 'error': 'Hazƒ±rlama ba≈üarƒ±sƒ±z'}
                        results['failed_datasets'] += 1
                        
                except Exception as e:
                    logger.error(f"Veri seti hazƒ±rlama hatasƒ± ({dataset_name}): {str(e)}")
                    results['datasets'][dataset_name] = {'prepared': False, 'error': str(e)}
                    results['failed_datasets'] += 1
            
            if results['successful_datasets'] == 0:
                results['success'] = False
            
            return results
            
        except Exception as e:
            logger.error(f"Veri hazƒ±rlama hatasƒ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _train_all_models(self) -> Dict[str, Any]:
        """T√ºm modelleri eƒüit"""
        try:
            logger.info("Model eƒüitimi ba≈ülatƒ±lƒ±yor...")
            results = self.trainer.train_all_models()
            
            # Sonu√ßlarƒ± analiz et
            successful_models = len([r for r in results.values() if 'error' not in r])
            failed_models = len([r for r in results.values() if 'error' in r])
            
            training_summary = {
                'success': successful_models > 0,
                'total_models': len(results),
                'successful_models': successful_models,
                'failed_models': failed_models,
                'results': results
            }
            
            # Ba≈üarƒ±lƒ± modelleri logla
            logger.info("üìä Eƒüitim Sonu√ßlarƒ±:")
            for model_name, result in results.items():
                if 'error' not in result:
                    logger.info(f"‚úÖ {model_name}: {result['final_accuracy']:.2f}% accuracy")
                else:
                    logger.error(f"‚ùå {model_name}: {result['error']}")
            
            return training_summary
            
        except Exception as e:
            logger.error(f"Model eƒüitimi hatasƒ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _validate_all_models(self) -> Dict[str, Any]:
        """T√ºm modelleri doƒürula"""
        try:
            logger.info("Model doƒürulamasƒ± ba≈ülatƒ±lƒ±yor...")
            results = self.validator.validate_all_models()
            
            # Sonu√ßlarƒ± analiz et
            successful_validations = len([r for r in results.values() if 'error' not in r])
            failed_validations = len([r for r in results.values() if 'error' in r])
            
            validation_summary = {
                'success': successful_validations > 0,
                'total_models': len(results),
                'successful_validations': successful_validations,
                'failed_validations': failed_validations,
                'results': results
            }
            
            # Doƒürulama sonu√ßlarƒ±nƒ± logla
            logger.info("üîç Doƒürulama Sonu√ßlarƒ±:")
            for model_name, result in results.items():
                if 'error' not in result:
                    logger.info(f"‚úÖ {model_name}: {result['accuracy']:.4f} accuracy")
                else:
                    logger.error(f"‚ùå {model_name}: {result['error']}")
            
            return validation_summary
            
        except Exception as e:
            logger.error(f"Model doƒürulamasƒ± hatasƒ±: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _create_pipeline_summary(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """Pipeline √∂zeti olu≈ütur"""
        summary = {
            'pipeline_success': pipeline_results.get('success', False),
            'steps_completed': pipeline_results.get('steps_completed', []),
            'total_duration': pipeline_results.get('total_duration', 0),
            'model_performance': {},
            'recommendations': []
        }
        
        # Model performanslarƒ±nƒ± √∂zetle
        if 'validation' in pipeline_results:
            validation_results = pipeline_results['validation']['results']
            
            for model_name, result in validation_results.items():
                if 'error' not in result:
                    summary['model_performance'][model_name] = {
                        'accuracy': result.get('accuracy', 0.0),
                        'precision': result.get('precision', 0.0),
                        'recall': result.get('recall', 0.0),
                        'f1_score': result.get('f1_score', 0.0),
                        'auc_roc': result.get('auc_roc', 0.0)
                    }
        
        # √ñneriler olu≈ütur
        if summary['model_performance']:
            best_model = max(summary['model_performance'].items(), 
                           key=lambda x: x[1]['accuracy'])
            summary['recommendations'].append(f"En iyi performans: {best_model[0]} ({best_model[1]['accuracy']:.4f})")
            
            # D√º≈ü√ºk performanslƒ± modelleri belirle
            low_performance = [name for name, perf in summary['model_performance'].items() 
                             if perf['accuracy'] < 0.8]
            if low_performance:
                summary['recommendations'].append(f"D√º≈ü√ºk performanslƒ± modeller: {', '.join(low_performance)}")
        
        return summary


def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(description='Profesyonel Tƒ±bbi AI Model Eƒüitim Sistemi')
    parser.add_argument('--skip-data', action='store_true', help='Veri hazƒ±rlamayƒ± atla')
    parser.add_argument('--skip-training', action='store_true', help='Model eƒüitimini atla')
    parser.add_argument('--skip-validation', action='store_true', help='Model doƒürulamasƒ±nƒ± atla')
    parser.add_argument('--models-dir', default='models', help='Modeller dizini')
    parser.add_argument('--data-dir', default='data', help='Veri dizini')
    parser.add_argument('--results-dir', default='results', help='Sonu√ßlar dizini')
    
    args = parser.parse_args()
    
    logger.info("üöÄ Profesyonel Tƒ±bbi AI Model Eƒüitim Sistemi Ba≈ülatƒ±lƒ±yor")
    logger.info(f"Modeller dizini: {args.models_dir}")
    logger.info(f"Veri dizini: {args.data_dir}")
    logger.info(f"Sonu√ßlar dizini: {args.results_dir}")
    
    # Pipeline olu≈ütur ve √ßalƒ±≈ütƒ±r
    pipeline = ProfessionalTrainingPipeline(
        models_dir=args.models_dir,
        data_dir=args.data_dir,
        results_dir=args.results_dir
    )
    
    # Tam pipeline'ƒ± √ßalƒ±≈ütƒ±r
    results = pipeline.run_complete_pipeline(
        skip_data_preparation=args.skip_data,
        skip_training=args.skip_training,
        skip_validation=args.skip_validation
    )
    
    # Sonu√ßlarƒ± √∂zetle
    if results['success']:
        logger.info("üéâ Pipeline ba≈üarƒ±yla tamamlandƒ±!")
        
        if 'summary' in results:
            summary = results['summary']
            logger.info("üìä √ñzet:")
            logger.info(f"  - Tamamlanan adƒ±mlar: {', '.join(summary['steps_completed'])}")
            logger.info(f"  - Toplam s√ºre: {summary['total_duration']:.2f} saniye")
            
            if summary['recommendations']:
                logger.info("üí° √ñneriler:")
                for rec in summary['recommendations']:
                    logger.info(f"  - {rec}")
    else:
        logger.error("‚ùå Pipeline ba≈üarƒ±sƒ±z!")
        if results['errors']:
            logger.error("Hatalar:")
            for error in results['errors']:
                logger.error(f"  - {error}")
    
    # Sonu√ßlarƒ± dosyaya kaydet
    import json
    results_file = Path(args.results_dir) / "pipeline_results.json"
    results_file.parent.mkdir(exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Sonu√ßlar kaydedildi: {results_file}")


if __name__ == "__main__":
    main()
