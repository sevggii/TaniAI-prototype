# TanÄ±AI Entegre Sistem Kurulum Rehberi

Bu rehber, Whisper + ML + LLM entegre sistemini kurmak ve kullanmak iÃ§in gerekli adÄ±mlarÄ± iÃ§erir.

## ğŸ¯ Sistem Ã–zellikleri

- **Whisper Large Model**: Ses dosyalarÄ±nÄ± TÃ¼rkÃ§e metne Ã§evirir
- **ML Triage Model**: Scikit-learn tabanlÄ± klinik Ã¶neri sistemi
- **LLM Entegrasyonu**: Ollama ile LLM tabanlÄ± akÄ±llÄ± analiz
- **Hibrit Sistem**: ML + LLM sonuÃ§larÄ±nÄ± birleÅŸtirerek daha doÄŸru Ã¶neriler

## ğŸ“‹ Gereksinimler

### Sistem Gereksinimleri
- Python 3.8+
- 8GB+ RAM (LLM iÃ§in)
- GPU Ã¶nerilir (Whisper iÃ§in)

### Python BaÄŸÄ±mlÄ±lÄ±klarÄ±
```bash
pip install -r ml_clinic/requirements.txt
```

## ğŸš€ Kurulum AdÄ±mlarÄ±

### ğŸ–¥ï¸ Yerel Kurulum (Windows/Linux/macOS)

#### 1. Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kurun
```bash
cd RANDEVU
pip install -r ml_clinic/requirements.txt
```

#### 2. Ollama Kurulumu (LLM iÃ§in)
```bash
# Ollama'yÄ± indirin ve kurun: https://ollama.ai/download

# KÃ¼Ã§Ã¼k model indirin (2B parametre)
ollama pull llama2:2b
# veya daha bÃ¼yÃ¼k model
ollama pull llama2:7b
```

#### 3. Ollama Servisini BaÅŸlatÄ±n
```bash
ollama serve
```

#### 4. Sistem Testini Ã‡alÄ±ÅŸtÄ±rÄ±n
```bash
cd RANDEVU
python test_integrated_system.py
```

### â˜ï¸ Cloud Kurulum (Google Colab/Kaggle)

#### 1. Google Colab'da Ã‡alÄ±ÅŸtÄ±r
- `TanÄ±AI_Cloud_Setup.ipynb` dosyasÄ±nÄ± Colab'a yÃ¼kleyin
- TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n
- Otomatik kurulum yapÄ±lacak

#### 2. Kaggle'da Ã‡alÄ±ÅŸtÄ±r
```python
# Kaggle notebook'unda
!curl -fsSL https://ollama.ai/install.sh | sh
!ollama pull llama2:2b
!ollama serve &
```

#### 3. Cloud Ã–zellikleri
- **Whisper Medium Model**: Cloud iÃ§in optimize edilmiÅŸ
- **Llama2:2b Model**: 2B parametre, hÄ±zlÄ± ve verimli
- **Otomatik Kurulum**: Tek tÄ±kla kurulum
- **Web EriÅŸimi**: Ngrok ile dÄ±ÅŸarÄ±dan eriÅŸim

## ğŸ”§ YapÄ±landÄ±rma

### Ã‡evre DeÄŸiÅŸkenleri (Opsiyonel)

```bash
# .env dosyasÄ± oluÅŸturun
LLM_PROVIDER=ollama
LLM_MODEL=llama2:7b
LLM_BASE_URL=http://localhost:11434
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=30

USE_ML=true
USE_LLM=true
ML_WEIGHT=0.6
LLM_WEIGHT=0.4
```

## ğŸ® KullanÄ±m

### 1. Sunucuyu BaÅŸlatÄ±n

```bash
cd RANDEVU/whisper_asr
python server.py
```

Sunucu `http://localhost:8001` adresinde Ã§alÄ±ÅŸacak.

### 2. API Endpoint'leri

#### Sistem Durumu
```bash
curl http://localhost:8001/whisper/system-status
```

#### Metin ile Klinik Ã–nerisi (ML)
```bash
curl -X POST "http://localhost:8001/whisper/clinic-from-text" \
  -F "text=BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum"
```

#### Metin ile Klinik Ã–nerisi (ML + LLM)
```bash
curl -X POST "http://localhost:8001/whisper/clinic-from-text-llm" \
  -F "text=BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum"
```

#### Ses DosyasÄ± ile Klinik Ã–nerisi (ML + LLM)
```bash
curl -X POST "http://localhost:8001/whisper/clinic-from-audio-llm" \
  -F "audio_file=@test_audio.wav"
```

### 3. Web ArayÃ¼zÃ¼

TarayÄ±cÄ±da `http://localhost:8001` adresine gidin.

## ğŸ“Š Test SenaryolarÄ±

### Ã–rnek Test Metinleri

```python
test_cases = [
    "BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum",
    "Ã‡ocuÄŸumda ateÅŸ ve Ã¶ksÃ¼rÃ¼k var", 
    "GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± ve nefes darlÄ±ÄŸÄ± Ã§ekiyorum",
    "DiÅŸ aÄŸrÄ±sÄ± dayanÄ±lmaz halde",
    "DepresyondayÄ±m ve uyuyamÄ±yorum",
    "KarÄ±n aÄŸrÄ±sÄ± ve ishal var"
]
```

### Beklenen SonuÃ§lar

- **BaÅŸ aÄŸrÄ±sÄ± + mide bulantÄ±sÄ±** â†’ NÃ¶roloji veya Ä°Ã§ HastalÄ±klarÄ±
- **Ã‡ocuk + ateÅŸ** â†’ Ã‡ocuk SaÄŸlÄ±ÄŸÄ± ve HastalÄ±klarÄ±
- **GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ±** â†’ Kardiyoloji
- **DiÅŸ aÄŸrÄ±sÄ±** â†’ DiÅŸ HekimliÄŸi
- **Depresyon** â†’ Ruh SaÄŸlÄ±ÄŸÄ± ve HastalÄ±klarÄ±
- **KarÄ±n aÄŸrÄ±sÄ±** â†’ Ä°Ã§ HastalÄ±klarÄ± (Dahiliye)

## ğŸ” Sorun Giderme

### LLM BaÄŸlantÄ± SorunlarÄ±

```bash
# Ollama durumunu kontrol edin
curl http://localhost:11434/api/tags

# Ollama'yÄ± yeniden baÅŸlatÄ±n
ollama serve
```

### Whisper Model SorunlarÄ±

```bash
# Whisper modelini yeniden indirin
pip uninstall openai-whisper
pip install openai-whisper
```

### ML Model SorunlarÄ±

```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yeniden kurun
pip install -r ml_clinic/requirements.txt
```

## ğŸ“ˆ Performans Optimizasyonu

### GPU KullanÄ±mÄ± (Whisper iÃ§in)

```python
# CUDA kullanÄ±mÄ± iÃ§in
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
```

### Model Boyutu SeÃ§imi

- **Whisper**: `large` (en iyi), `medium` (orta), `small` (hÄ±zlÄ±)
- **LLM**: `llama2:7b` (en iyi), `llama2:2b` (hÄ±zlÄ±)

### Bellek Optimizasyonu

```python
# KÃ¼Ã§Ã¼k modeller iÃ§in
LLM_MODEL=llama2:2b
WHISPER_MODEL=small
```

## ğŸš¨ Acil Durum Tespiti

Sistem aÅŸaÄŸÄ±daki durumlarÄ± acil olarak tespit eder:

- **Kalp krizi belirtileri**: GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± + soÄŸuk terleme
- **Ä°nme belirtileri**: Ani yÃ¼z kaymasÄ± + konuÅŸma bozukluÄŸu
- **Åiddetli travma**: BilinÃ§ kaybÄ± + kanama
- **Gebelik acil**: Hamilelik + ÅŸiddetli aÄŸrÄ±

Bu durumlarda sistem "ACIL" yanÄ±tÄ± verir ve 112 aranmasÄ±nÄ± Ã¶nerir.

## ğŸ“ Log DosyalarÄ±

```bash
# Log dosyalarÄ±nÄ± kontrol edin
tail -f logs/system.log
```

## ğŸ”„ GÃ¼ncelleme

```bash
# Sistemi gÃ¼ncelleyin
git pull
pip install -r ml_clinic/requirements.txt
python test_integrated_system.py
```

## ğŸ“ Destek

Sorunlar iÃ§in:
1. `test_integrated_system.py` Ã§alÄ±ÅŸtÄ±rÄ±n
2. Log dosyalarÄ±nÄ± kontrol edin
3. Sistem gereksinimlerini doÄŸrulayÄ±n

## ğŸ¯ Gelecek GeliÅŸtirmeler

- [ ] Daha fazla LLM modeli desteÄŸi
- [ ] Web arayÃ¼zÃ¼ iyileÅŸtirmeleri
- [ ] GerÃ§ek zamanlÄ± ses analizi
- [ ] Ã‡oklu dil desteÄŸi
- [ ] Mobil uygulama
