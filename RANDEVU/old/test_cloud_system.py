#!/usr/bin/env python3
"""
Cloud OrtamÄ± Test Scripti
Google Colab, Kaggle gibi ortamlar iÃ§in optimize edilmiÅŸ
"""

import os
import sys
import json
import requests
import subprocess
import time
from pathlib import Path

def detect_environment():
    """Ortam tespiti"""
    print("ðŸ” Ortam tespit ediliyor...")
    
    environments = {
        "colab": False,
        "kaggle": False,
        "local": False
    }
    
    # Google Colab kontrolÃ¼
    try:
        import google.colab
        environments["colab"] = True
        print("âœ… Google Colab ortamÄ± tespit edildi")
    except ImportError:
        pass
    
    # Kaggle kontrolÃ¼
    if os.path.exists("/kaggle/input") or "KAGGLE" in os.environ:
        environments["kaggle"] = True
        print("âœ… Kaggle ortamÄ± tespit edildi")
    
    # Yerel ortam
    if not environments["colab"] and not environments["kaggle"]:
        environments["local"] = True
        print("âœ… Yerel ortam tespit edildi")
    
    return environments

def test_ollama_cloud():
    """Cloud ortamÄ±nda Ollama testi"""
    print("\nðŸ¤– Ollama Cloud Testi...")
    
    try:
        # Ollama servisini baÅŸlat
        print("Ollama servisi baÅŸlatÄ±lÄ±yor...")
        process = subprocess.Popen(
            ['ollama', 'serve'], 
            stdout=subprocess.DEVNULL, 
            stderr=subprocess.DEVNULL
        )
        
        # Servisin baÅŸlamasÄ±nÄ± bekle
        time.sleep(5)
        
        # Ollama API'sini test et
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        
        if response.status_code == 200:
            models = response.json().get("models", [])
            print(f"âœ… Ollama Ã§alÄ±ÅŸÄ±yor, {len(models)} model mevcut")
            
            # KÃ¼Ã§Ã¼k model var mÄ± kontrol et
            small_models = [m["name"] for m in models if "2b" in m["name"] or "1b" in m["name"]]
            if small_models:
                print(f"âœ… KÃ¼Ã§Ã¼k modeller: {small_models}")
                return True
            else:
                print("âš ï¸ KÃ¼Ã§Ã¼k model bulunamadÄ±, indiriliyor...")
                return download_small_model()
        else:
            print(f"âŒ Ollama API hatasÄ±: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Ollama test hatasÄ±: {e}")
        return False

def download_small_model():
    """KÃ¼Ã§Ã¼k model indir"""
    print("ðŸ“¥ KÃ¼Ã§Ã¼k model indiriliyor...")
    
    small_models = ["llama2:2b", "phi:2b", "tinyllama:1.1b"]
    
    for model in small_models:
        try:
            print(f"Model indiriliyor: {model}")
            result = subprocess.run(
                ["ollama", "pull", model], 
                capture_output=True, 
                text=True, 
                timeout=300
            )
            
            if result.returncode == 0:
                print(f"âœ… {model} baÅŸarÄ±yla indirildi")
                return True
            else:
                print(f"âŒ {model} indirme hatasÄ±")
                
        except subprocess.TimeoutExpired:
            print(f"â° {model} indirme timeout")
            continue
        except Exception as e:
            print(f"âŒ {model} hatasÄ±: {e}")
            continue
    
    print("âŒ HiÃ§bir kÃ¼Ã§Ã¼k model indirilemedi")
    return False

def test_whisper_cloud():
    """Cloud ortamÄ±nda Whisper testi"""
    print("\nðŸŽ¤ Whisper Cloud Testi...")
    
    try:
        import whisper
        
        # Medium model kullan (cloud iÃ§in optimize)
        print("Whisper Medium modeli yÃ¼kleniyor...")
        model = whisper.load_model("medium")
        
        print(f"âœ… Whisper Medium modeli yÃ¼klendi")
        print(f"Model boyutu: {model.dims}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Whisper test hatasÄ±: {e}")
        return False

def test_ml_model_cloud():
    """Cloud ortamÄ±nda ML model testi"""
    print("\nðŸ§  ML Model Cloud Testi...")
    
    try:
        # Proje yolu ekle
        project_root = Path(__file__).parent
        sys.path.insert(0, str(project_root))
        
        from ml_clinic.triage_model import get_triage_model
        
        model = get_triage_model()
        result = model.suggest("BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum", top_k=3)
        
        print(f"âœ… ML Model Ã§alÄ±ÅŸÄ±yor")
        print(f"Ã–neriler: {result.get('suggestions', [])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ML Model test hatasÄ±: {e}")
        return False

def test_cloud_llm():
    """Cloud LLM testi"""
    print("\nâ˜ï¸ Cloud LLM Testi...")
    
    try:
        from cloud_llm_analyzer import CloudLLMAnalyzer, CloudLLMConfig
        
        config = CloudLLMConfig(
            provider="ollama",
            model="llama2:2b",
            base_url="http://localhost:11434"
        )
        
        analyzer = CloudLLMAnalyzer(config)
        
        # Test metni
        test_text = "BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum"
        result = analyzer.analyze_with_cloud_llm(test_text)
        
        print(f"âœ… Cloud LLM Ã§alÄ±ÅŸÄ±yor")
        print(f"Test: {test_text}")
        print(f"Ã–neri: {result.get('clinic', 'Bilinmeyen')}")
        print(f"GÃ¼ven: {result.get('confidence', 0):.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Cloud LLM test hatasÄ±: {e}")
        return False

def test_integrated_cloud():
    """Entegre cloud sistemi testi"""
    print("\nðŸ”„ Entegre Cloud Sistem Testi...")
    
    try:
        from ml_clinic.integrated_triage import get_integrated_triage, TriageConfig
        from ml_clinic.llm_clinic_analyzer import LLMConfig
        
        # Config'leri ayarla
        llm_config = LLMConfig(
            provider="ollama",
            model="llama2:2b",
            base_url="http://localhost:11434"
        )
        
        triage_config = TriageConfig(
            use_ml=True,
            use_llm=True,
            ml_weight=0.6,
            llm_weight=0.4
        )
        
        # Entegre sistemi baÅŸlat
        integrated_triage = get_integrated_triage(triage_config, llm_config)
        
        # Test senaryolarÄ±
        test_cases = [
            "BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum",
            "Ã‡ocuÄŸumda ateÅŸ ve Ã¶ksÃ¼rÃ¼k var",
            "GÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ± ve nefes darlÄ±ÄŸÄ± Ã§ekiyorum",
            "DiÅŸ aÄŸrÄ±sÄ± dayanÄ±lmaz halde"
        ]
        
        print(f"âœ… Entegre sistem Ã§alÄ±ÅŸÄ±yor")
        print(f"\nðŸ“ Test SonuÃ§larÄ±:")
        
        for i, test_text in enumerate(test_cases, 1):
            result = integrated_triage.suggest(test_text, top_k=3)
            print(f"\n{i}. {test_text}")
            print(f"   Ã–neriler: {result.get('suggestions', [])}")
            print(f"   YÃ¶ntemler: {result.get('methods_used', [])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Entegre sistem test hatasÄ±: {e}")
        return False

def test_web_server_cloud():
    """Cloud web sunucusu testi"""
    print("\nðŸŒ Cloud Web Sunucusu Testi...")
    
    try:
        import subprocess
        import threading
        import time
        
        def start_server():
            try:
                subprocess.run([
                    'python', 'whisper_asr/server.py'
                ], cwd=Path(__file__).parent)
            except Exception as e:
                print(f"Sunucu hatasÄ±: {e}")
        
        # Sunucuyu arka planda baÅŸlat
        server_thread = threading.Thread(target=start_server)
        server_thread.daemon = True
        server_thread.start()
        
        # Sunucunun baÅŸlamasÄ±nÄ± bekle
        time.sleep(5)
        
        # API'yi test et
        try:
            response = requests.get("http://localhost:8001/whisper/status", timeout=10)
            if response.status_code == 200:
                print("âœ… Web sunucusu Ã§alÄ±ÅŸÄ±yor")
                print("ðŸŒ Web arayÃ¼zÃ¼: http://localhost:8001")
                return True
            else:
                print(f"âŒ Web sunucusu hatasÄ±: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ Web sunucusu baÄŸlantÄ± hatasÄ±: {e}")
            return False
        
    except Exception as e:
        print(f"âŒ Web sunucusu test hatasÄ±: {e}")
        return False

def main():
    """Ana test fonksiyonu"""
    print("â˜ï¸ TanÄ±AI Cloud Sistem Testi BaÅŸlÄ±yor...")
    print("=" * 60)
    
    # Ortam tespiti
    environments = detect_environment()
    
    # Testleri Ã§alÄ±ÅŸtÄ±r
    tests = [
        ("Whisper Model", test_whisper_cloud),
        ("ML Model", test_ml_model_cloud),
        ("Ollama", test_ollama_cloud),
        ("Cloud LLM", test_cloud_llm),
        ("Entegre Sistem", test_integrated_cloud),
        ("Web Sunucusu", test_web_server_cloud),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} testi beklenmeyen hata: {e}")
            results[test_name] = False
    
    # SonuÃ§larÄ± Ã¶zetle
    print("\n" + "=" * 60)
    print("ðŸ“Š CLOUD TEST SONUÃ‡LARI")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… BAÅžARILI" if result else "âŒ BAÅžARISIZ"
        print(f"{test_name:20} : {status}")
        if result:
            passed += 1
    
    print(f"\nToplam: {passed}/{total} test baÅŸarÄ±lÄ±")
    
    # Ortam bilgisi
    if environments["colab"]:
        print("\nðŸ“± Google Colab ortamÄ±nda Ã§alÄ±ÅŸÄ±yor")
    elif environments["kaggle"]:
        print("\nðŸ† Kaggle ortamÄ±nda Ã§alÄ±ÅŸÄ±yor")
    else:
        print("\nðŸ–¥ï¸ Yerel ortamda Ã§alÄ±ÅŸÄ±yor")
    
    # SonuÃ§
    if passed == total:
        print("ðŸŽ‰ TÃ¼m testler baÅŸarÄ±lÄ±! Cloud sistemi kullanÄ±ma hazÄ±r.")
    elif passed >= total - 1:
        print("âš ï¸ Ã‡oÄŸu test baÅŸarÄ±lÄ±. Sistem Ã§alÄ±ÅŸabilir.")
    else:
        print("âŒ BirÃ§ok test baÅŸarÄ±sÄ±z. Kurulumu kontrol edin.")
    
    # Ã–neriler
    print("\nðŸ’¡ CLOUD Ã–NERÄ°LERÄ°:")
    if not results.get("Ollama", False):
        print("   - Ollama kurulumunu kontrol edin")
        print("   - KÃ¼Ã§Ã¼k model indirin: ollama pull llama2:2b")
    
    if not results.get("Web Sunucusu", False):
        print("   - Web sunucusu portunu kontrol edin")
        print("   - Ngrok ile dÄ±ÅŸarÄ±dan eriÅŸim saÄŸlayÄ±n")
    
    if environments["colab"]:
        print("   - Colab'da ngrok kullanarak web eriÅŸimi saÄŸlayÄ±n")
        print("   - GPU kullanÄ±mÄ± iÃ§in Runtime > Change runtime type > GPU")

if __name__ == "__main__":
    main()
