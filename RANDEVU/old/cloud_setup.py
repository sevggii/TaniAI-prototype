#!/usr/bin/env python3
"""
Cloud OrtamÄ± iÃ§in TanÄ±AI Kurulum Scripti
Google Colab, Kaggle, AWS, Azure gibi ortamlar iÃ§in optimize edilmiÅŸ
"""

import os
import sys
import subprocess
import requests
import json
from pathlib import Path

def install_requirements():
    """Gerekli paketleri kur"""
    print("ğŸ“¦ Gerekli paketler kuruluyor...")
    
    requirements = [
        "openai-whisper",
        "torch",
        "torchaudio", 
        "scikit-learn",
        "pandas",
        "numpy",
        "fastapi",
        "uvicorn",
        "python-multipart",
        "requests",
        "aiohttp"
    ]
    
    for req in requirements:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", req])
            print(f"âœ… {req} kuruldu")
        except subprocess.CalledProcessError as e:
            print(f"âŒ {req} kurulum hatasÄ±: {e}")

def setup_cloud_llm():
    """Cloud-friendly LLM kurulumu"""
    print("\nğŸ¤– Cloud LLM kurulumu...")
    
    # OpenAI API key kontrolÃ¼
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        print("âœ… OpenAI API key bulundu")
        return "openai"
    
    # Hugging Face kontrolÃ¼
    hf_token = os.getenv("HUGGINGFACE_TOKEN")
    if hf_token:
        print("âœ… Hugging Face token bulundu")
        return "huggingface"
    
    # Google Colab kontrolÃ¼
    try:
        import google.colab
        print("âœ… Google Colab ortamÄ± tespit edildi")
        return "colab"
    except ImportError:
        pass
    
    print("âš ï¸ Cloud LLM servisi bulunamadÄ±, sadece ML modeli kullanÄ±lacak")
    return "ml_only"

def download_whisper_model():
    """Whisper modelini indir"""
    print("\nğŸ¤ Whisper modeli indiriliyor...")
    
    try:
        import whisper
        # Cloud ortamÄ±nda daha kÃ¼Ã§Ã¼k model kullan
        model_size = "medium"  # large yerine medium (daha az RAM)
        print(f"Model boyutu: {model_size}")
        
        model = whisper.load_model(model_size)
        print(f"âœ… Whisper {model_size} modeli yÃ¼klendi")
        return True
    except Exception as e:
        print(f"âŒ Whisper model hatasÄ±: {e}")
        return False

def test_ml_model():
    """ML modelini test et"""
    print("\nğŸ§  ML modeli test ediliyor...")
    
    try:
        from ml_clinic.triage_model import get_triage_model
        model = get_triage_model()
        
        test_text = "BaÅŸ aÄŸrÄ±m var ve mide bulantÄ±sÄ± yaÅŸÄ±yorum"
        result = model.suggest(test_text, top_k=3)
        
        print(f"âœ… ML Model Ã§alÄ±ÅŸÄ±yor")
        print(f"   Test: {test_text}")
        print(f"   Ã–neriler: {result.get('suggestions', [])}")
        return True
    except Exception as e:
        print(f"âŒ ML Model hatasÄ±: {e}")
        return False

def create_cloud_config():
    """Cloud ortamÄ± iÃ§in yapÄ±landÄ±rma oluÅŸtur"""
    print("\nâš™ï¸ Cloud yapÄ±landÄ±rmasÄ± oluÅŸturuluyor...")
    
    config = {
        "environment": "cloud",
        "whisper_model": "medium",
        "llm_provider": "openai",  # veya huggingface
        "llm_model": "gpt-3.5-turbo",
        "use_ml": True,
        "use_llm": True,
        "ml_weight": 0.7,
        "llm_weight": 0.3
    }
    
    # Ã‡evre deÄŸiÅŸkenlerini ayarla
    os.environ["LLM_PROVIDER"] = config["llm_provider"]
    os.environ["LLM_MODEL"] = config["llm_model"]
    os.environ["USE_ML"] = "true"
    os.environ["USE_LLM"] = "true"
    
    with open("cloud_config.json", "w") as f:
        json.dump(config, f, indent=2)
    
    print("âœ… Cloud yapÄ±landÄ±rmasÄ± oluÅŸturuldu")
    return config

def start_cloud_server():
    """Cloud sunucusunu baÅŸlat"""
    print("\nğŸš€ Cloud sunucusu baÅŸlatÄ±lÄ±yor...")
    
    try:
        from whisper_asr.server import app
        import uvicorn
        
        print("Sunucu baÅŸlatÄ±lÄ±yor...")
        print("ğŸŒ Web arayÃ¼zÃ¼: http://localhost:8001")
        print("ğŸ“¡ API: http://localhost:8001/whisper/")
        
        uvicorn.run(app, host="0.0.0.0", port=8001)
        
    except Exception as e:
        print(f"âŒ Sunucu baÅŸlatma hatasÄ±: {e}")

def main():
    """Ana kurulum fonksiyonu"""
    print("â˜ï¸ TanÄ±AI Cloud Kurulumu BaÅŸlÄ±yor...")
    print("=" * 50)
    
    # 1. Gerekli paketleri kur
    install_requirements()
    
    # 2. Cloud LLM kurulumu
    llm_type = setup_cloud_llm()
    
    # 3. Whisper modelini indir
    whisper_ok = download_whisper_model()
    
    # 4. ML modelini test et
    ml_ok = test_ml_model()
    
    # 5. Cloud yapÄ±landÄ±rmasÄ±
    config = create_cloud_config()
    
    # 6. SonuÃ§larÄ± gÃ¶ster
    print("\n" + "=" * 50)
    print("ğŸ“Š KURULUM SONUÃ‡LARI")
    print("=" * 50)
    
    print(f"Whisper Model: {'âœ…' if whisper_ok else 'âŒ'}")
    print(f"ML Model: {'âœ…' if ml_ok else 'âŒ'}")
    print(f"LLM Provider: {llm_type}")
    print(f"Environment: Cloud")
    
    if whisper_ok and ml_ok:
        print("\nğŸ‰ Kurulum baÅŸarÄ±lÄ±! Sunucu baÅŸlatÄ±lÄ±yor...")
        start_cloud_server()
    else:
        print("\nâŒ Kurulum tamamlanamadÄ±. HatalarÄ± kontrol edin.")

if __name__ == "__main__":
    main()
