import pandas as pd
import numpy as np
import joblib
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV

# XGBoost i√ßin
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("‚ö†Ô∏è XGBoost kurulu deƒüil. pip install xgboost ile kurabilirsiniz.")

class AdvancedDiseasePredictor:
    def __init__(self):
        self.models = {}
        self.ensemble_model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_selector = None
        self.feature_names = None
        self.best_model = None
        self.results = {}
        
    def load_data(self, csv_path):
        """Veri setini y√ºkler ve hazƒ±rlar"""
        print("üìä Veri seti y√ºkleniyor...")
        self.df = pd.read_csv(csv_path)
        
        # X ve y ayƒ±r
        self.X = self.df.drop("Etiket", axis=1)
        self.y = self.df["Etiket"]
        
        # Etiketleri encode et
        self.y_encoded = self.label_encoder.fit_transform(self.y)
        
        # √ñzellik isimlerini sakla
        self.feature_names = self.X.columns.tolist()
        
        print(f"‚úÖ Veri y√ºklendi: {self.X.shape[0]} √∂rnek, {self.X.shape[1]} √∂zellik")
        print(f"üìã Sƒ±nƒ±flar: {list(self.label_encoder.classes_)}")
        
        return self.X, self.y_encoded
    
    def create_advanced_features(self, X):
        """Geli≈ümi≈ü √∂zellik m√ºhendisliƒüi"""
        print("üîß Geli≈ümi≈ü √∂zellik m√ºhendisliƒüi yapƒ±lƒ±yor...")
        
        X_enhanced = X.copy()
        
        # 1. Semptom kombinasyon skorlarƒ±
        if "Ate≈ü" in X.columns and "Koku veya Tat Kaybƒ±" in X.columns:
            X_enhanced["COVID_Indicator"] = X["Ate≈ü"] * X["Koku veya Tat Kaybƒ±"] * X["Nefes Darlƒ±ƒüƒ±"]
        
        if "Ate≈ü" in X.columns and "V√ºcut Aƒürƒ±larƒ±" in X.columns:
            X_enhanced["Grip_Indicator"] = X["Ate≈ü"] * X["V√ºcut Aƒürƒ±larƒ±"] * X["Bitkinlik"]
        
        if "Burun Akƒ±ntƒ±sƒ± veya Tƒ±kanƒ±klƒ±ƒüƒ±" in X.columns and "Hap≈üƒ±rma" in X.columns:
            X_enhanced["Cold_Indicator"] = X["Burun Akƒ±ntƒ±sƒ± veya Tƒ±kanƒ±klƒ±ƒüƒ±"] * X["Hap≈üƒ±rma"] * (1 - X.get("Ate≈ü", 0))
        
        if "G√∂z Ka≈üƒ±ntƒ±sƒ± veya Sulanma" in X.columns and "Hap≈üƒ±rma" in X.columns:
            X_enhanced["Allergy_Indicator"] = X["G√∂z Ka≈üƒ±ntƒ±sƒ± veya Sulanma"] * X["Hap≈üƒ±rma"] * (1 - X.get("Ate≈ü", 0))
        
        # 2. Toplam semptom ≈üiddeti
        X_enhanced["Total_Symptom_Severity"] = X.sum(axis=1)
        
        # 3. Semptom sayƒ±sƒ±
        X_enhanced["Symptom_Count"] = (X > 0.1).sum(axis=1)
        
        # 4. Solunum sistemi skoru
        respiratory_symptoms = ["Nefes Darlƒ±ƒüƒ±", "√ñks√ºr√ºk", "Burun Akƒ±ntƒ±sƒ± veya Tƒ±kanƒ±klƒ±ƒüƒ±"]
        available_resp = [s for s in respiratory_symptoms if s in X.columns]
        if available_resp:
            X_enhanced["Respiratory_Score"] = X[available_resp].mean(axis=1)
        
        # 5. Sistemik semptom skoru
        systemic_symptoms = ["Ate≈ü", "Bitkinlik", "V√ºcut Aƒürƒ±larƒ±", "Ba≈ü Aƒürƒ±sƒ±"]
        available_syst = [s for s in systemic_symptoms if s in X.columns]
        if available_syst:
            X_enhanced["Systemic_Score"] = X[available_syst].mean(axis=1)
        
        # 6. Gastrointestinal semptom skoru
        gi_symptoms = ["Bulantƒ± veya Kusma", "ƒ∞shal", "ƒ∞≈ütahsƒ±zlƒ±k"]
        available_gi = [s for s in gi_symptoms if s in X.columns]
        if available_gi:
            X_enhanced["GI_Score"] = X[available_gi].mean(axis=1)
        
        print(f"‚úÖ √ñzellik sayƒ±sƒ± {X.shape[1]}'den {X_enhanced.shape[1]}'e √ßƒ±karƒ±ldƒ±")
        
        return X_enhanced
    
    def train_individual_models(self, X, y):
        """Bireysel modelleri eƒüitir"""
        print("ü§ñ Bireysel modeller eƒüitiliyor...")
        
        # 1. Random Forest (Optimized)
        print("üå≤ Random Forest eƒüitiliyor...")
        rf_params = {
            'n_estimators': 200,
            'max_depth': 10,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'max_features': 'sqrt',
            'bootstrap': True,
            'random_state': 42,
            'n_jobs': -1
        }
        self.models['RandomForest'] = RandomForestClassifier(**rf_params)
        
        # 2. XGBoost (if available)
        if XGBOOST_AVAILABLE:
            print("üöÄ XGBoost eƒüitiliyor...")
            xgb_params = {
                'n_estimators': 200,
                'max_depth': 6,
                'learning_rate': 0.1,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'eval_metric': 'mlogloss'
            }
            self.models['XGBoost'] = xgb.XGBClassifier(**xgb_params)
        
        # 3. SVM
        print("‚ö° SVM eƒüitiliyor...")
        self.models['SVM'] = SVC(
            kernel='rbf',
            C=10,
            gamma='scale',
            probability=True,
            random_state=42
        )
        
        # 4. Neural Network
        print("üß† Neural Network eƒüitiliyor...")
        self.models['NeuralNetwork'] = MLPClassifier(
            hidden_layer_sizes=(100, 50, 25),
            activation='relu',
            solver='adam',
            alpha=0.001,
            learning_rate='adaptive',
            max_iter=500,
            random_state=42
        )
        
        # 5. Logistic Regression
        print("üìà Logistic Regression eƒüitiliyor...")
        self.models['LogisticRegression'] = LogisticRegression(
            C=10,
            max_iter=1000,
            random_state=42,
            multi_class='ovr'
        )
        
        # Her modeli eƒüit ve deƒüerlendir
        for name, model in self.models.items():
            print(f"üîÑ {name} eƒüitiliyor...")
            
            # Cross validation
            cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
            self.results[name] = {
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'cv_scores': cv_scores
            }
            
            print(f"‚úÖ {name} - CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
        
        return self.results
    
    def create_ensemble_model(self, X, y):
        """Ensemble model olu≈üturur"""
        print("üé≠ Ensemble model olu≈üturuluyor...")
        
        # En iyi modelleri se√ß
        best_models = []
        for name, result in self.results.items():
            if result['cv_mean'] > 0.85:  # %85'ten y√ºksek performans g√∂steren modeller
                best_models.append((name, self.models[name]))
                print(f"‚úÖ {name} ensemble'a eklendi")
        
        if len(best_models) < 2:
            print("‚ö†Ô∏è Yeterli model yok, t√ºm modelleri kullanƒ±yor...")
            best_models = [(name, model) for name, model in self.models.items()]
        
        # Voting Classifier
        self.ensemble_model = VotingClassifier(
            estimators=best_models,
            voting='soft',  # Olasƒ±lƒ±k tabanlƒ± voting
            n_jobs=-1
        )
        
        print(f"üéØ {len(best_models)} model ile ensemble olu≈üturuldu")
        return self.ensemble_model
    
    def hyperparameter_tuning(self, X, y):
        """Hiperparametre optimizasyonu"""
        print("üéõÔ∏è Hiperparametre optimizasyonu ba≈ülƒ±yor...")
        
        # Random Forest i√ßin grid search
        rf_params = {
            'n_estimators': [100, 200, 300],
            'max_depth': [8, 10, 12, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        print("üå≤ Random Forest hiperparametre optimizasyonu...")
        rf_grid = GridSearchCV(
            RandomForestClassifier(random_state=42),
            rf_params,
            cv=3,
            scoring='accuracy',
            n_jobs=-1,
            verbose=1
        )
        rf_grid.fit(X, y)
        
        print(f"‚úÖ En iyi RF parametreleri: {rf_grid.best_params_}")
        print(f"‚úÖ En iyi RF skoru: {rf_grid.best_score_:.4f}")
        
        # En iyi Random Forest'i g√ºncelle
        self.models['RandomForest_Optimized'] = rf_grid.best_estimator_
        
        # XGBoost optimizasyonu (if available)
        if XGBOOST_AVAILABLE:
            print("üöÄ XGBoost hiperparametre optimizasyonu...")
            xgb_params = {
                'n_estimators': [100, 200],
                'max_depth': [4, 6, 8],
                'learning_rate': [0.05, 0.1, 0.2],
                'subsample': [0.8, 0.9]
            }
            
            xgb_grid = GridSearchCV(
                xgb.XGBClassifier(random_state=42, eval_metric='mlogloss'),
                xgb_params,
                cv=3,
                scoring='accuracy',
                n_jobs=-1,
                verbose=1
            )
            xgb_grid.fit(X, y)
            
            print(f"‚úÖ En iyi XGB parametreleri: {xgb_grid.best_params_}")
            print(f"‚úÖ En iyi XGB skoru: {xgb_grid.best_score_:.4f}")
            
            self.models['XGBoost_Optimized'] = xgb_grid.best_estimator_
        
        return self.models
    
    def train_complete_system(self, csv_path):
        """T√ºm sistemi eƒüitir"""
        print("üöÄ Geli≈ümi≈ü hastalƒ±k tanƒ± sistemi eƒüitimi ba≈ülƒ±yor...\n")
        
        # 1. Veri y√ºkle
        X, y = self.load_data(csv_path)
        
        # 2. Train/test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # 3. √ñzellik m√ºhendisliƒüi
        X_train_enhanced = self.create_advanced_features(X_train)
        X_test_enhanced = self.create_advanced_features(X_test)
        
        # 4. √ñl√ßeklendirme
        X_train_scaled = self.scaler.fit_transform(X_train_enhanced)
        X_test_scaled = self.scaler.transform(X_test_enhanced)
        
        # 5. √ñzellik se√ßimi
        self.feature_selector = SelectKBest(f_classif, k=min(20, X_train_scaled.shape[1]))
        X_train_selected = self.feature_selector.fit_transform(X_train_scaled, y_train)
        X_test_selected = self.feature_selector.transform(X_test_scaled)
        
        print(f"üéØ √ñzellik se√ßimi: {X_train_scaled.shape[1]} -> {X_train_selected.shape[1]}")
        
        # 6. Bireysel modelleri eƒüit
        self.train_individual_models(X_train_selected, y_train)
        
        # 7. Hiperparametre optimizasyonu
        self.hyperparameter_tuning(X_train_selected, y_train)
        
        # 8. Ensemble model olu≈ütur
        self.create_ensemble_model(X_train_selected, y_train)
        
        # 9. Final deƒüerlendirme
        print("\nüéØ Final deƒüerlendirme:")
        
        # En iyi bireysel modeli bul
        best_individual = max(self.results.items(), key=lambda x: x[1]['cv_mean'])
        print(f"üèÜ En iyi bireysel model: {best_individual[0]} ({best_individual[1]['cv_mean']:.4f})")
        
        # Ensemble modeli test et
        if self.ensemble_model:
            ensemble_cv = cross_val_score(self.ensemble_model, X_train_selected, y_train, cv=5)
            print(f"üé≠ Ensemble CV Score: {ensemble_cv.mean():.4f} (¬±{ensemble_cv.std():.4f})")
            
            # Test seti √ºzerinde deƒüerlendir
            self.ensemble_model.fit(X_train_selected, y_train)
            y_pred = self.ensemble_model.predict(X_test_selected)
            y_pred_proba = self.ensemble_model.predict_proba(X_test_selected)
            
            test_accuracy = accuracy_score(y_test, y_pred)
            print(f"üéØ Test Accuracy: {test_accuracy:.4f}")
            
            print("\nüìä Detaylƒ± Sƒ±nƒ±flandƒ±rma Raporu:")
            print(classification_report(y_test, y_pred, target_names=self.label_encoder.classes_))
            
            # En iyi modeli kaydet
            self.best_model = self.ensemble_model
            
        return {
            'best_individual': best_individual,
            'ensemble_cv': ensemble_cv.mean() if self.ensemble_model else None,
            'test_accuracy': test_accuracy if self.ensemble_model else None,
            'models': self.models,
            'feature_names': self.feature_names
        }
    
    def save_model(self, model_path="advanced_disease_model.pkl"):
        """Modeli kaydeder"""
        if self.best_model:
            model_data = {
                'model': self.best_model,
                'scaler': self.scaler,
                'label_encoder': self.label_encoder,
                'feature_selector': self.feature_selector,
                'feature_names': self.feature_names
            }
            joblib.dump(model_data, model_path)
            print(f"üíæ Model kaydedildi: {model_path}")
        else:
            print("‚ö†Ô∏è Kaydedilecek model yok!")

# Kullanƒ±m √∂rneƒüi
if __name__ == "__main__":
    # Geli≈ümi≈ü veri seti √ºret (eƒüer yoksa)
    try:
        df = pd.read_csv("enhanced_hastalik_veriseti.csv")
        print("‚úÖ Geli≈ümi≈ü veri seti bulundu")
    except FileNotFoundError:
        print("‚ö†Ô∏è Geli≈ümi≈ü veri seti bulunamadƒ±, √∂nce enhanced_data_generation.py √ßalƒ±≈ütƒ±rƒ±n")
        exit(1)
    
    # Sistem eƒüitimi
    predictor = AdvancedDiseasePredictor()
    results = predictor.train_complete_system("enhanced_hastalik_veriseti.csv")
    
    # Modeli kaydet
    predictor.save_model("advanced_disease_model.pkl")
    
    print("\nüéâ Sistem eƒüitimi tamamlandƒ±!")
    print(f"üèÜ En iyi performans: {results['test_accuracy']:.4f}")
